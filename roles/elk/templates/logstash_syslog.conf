input {
  syslog {
      type => "syslog"
      host => "{{ internal_ip }}"
  }
  tcp {

    type => "logstash"
    host => "{{ internal_ip }}"
    port => {{ global_syslog_server_json_port }}
    codec => json_lines
  }
}
filter {
  if [type] == "syslog" {
        grok {
            match => {
                "message" => [
                # for each message kind we have a rule
                # you can create rules with https://grokdebug.herokuapp.com/
                    '<%{NONNEGINT:syslog5424_pri}>%{SYSLOGTIMESTAMP:timestamp} sudo:  %{DATA:sudoer_userid} : TTY=%{DATA:tty} ; PWD=%{DATA:pwd} ; USER=%{DATA:sudo_userid} ; COMMAND=%{GREEDYDATA:command}',
                    '<%{NONNEGINT:syslog5424_pri}>%{SYSLOGTIMESTAMP:timestamp} /usr/sbin/cron\[%{NONNEGINT:pid}]: (%{DATA:cron_userid}) CMD (%{DATA:command})',

                # last rule is generic arbitrary message with arbitrary key=value in the end
                    '<%{NONNEGINT:syslog5424_pri}>%{SYSLOGTIMESTAMP:timestamp} %{DATA:sender}: %{GREEDYDATA:syslog_msg}(?<kvpairs>([^=]+=[^ ,]+,? +)*)'
                    ]
            }
        }
        # this allows to split each key/values into one field inside the event (done in conjonction with the last grok rule)
        kv {
            source => "kvpairs"
            trim => "<>\[\],"

            remove_field => [ "kvpairs" ] # Delete the field afterwards
        }
    }

    mutate {
      add_field => { "hostname" => "%{host}" }
    }
    dns {
      action => "replace"
      reverse => [ "hostname" ]
    }
}

output {
    elasticsearch { hosts => ["{{ internal_ip }}:{{ elastic_port }}"] }
    stdout { codec => rubydebug }
}
